---
name: English Issue Template
about: Issues related to this project
---

*Hint: Fill in the [ ] with an x to mark it as checked. Delete any option that is not related to this issue.*

### Describe the issue in detail

*Please describe the problem you encountered as specifically as possible. If possible, please copy-and-paste your running command. This will help us locate the issue more quickly.*

### Provide screenshots or logs

*(If necessary) Please provide a text log or screenshot to help us better understand the issue details.*


### MUST check (delete irrelevant items)

- [ ] **Base model**: LLaMA  / Alpaca / LLaMA-Plus / Alpaca-Plus
- [ ] **Operating System**: Windows / MacOS / Linux
- [ ] **Issue type**: Download / Model conversion and merging / Pretraining and SFT / Inference (ðŸ¤— transformers) / Quantization and deployment (llama.cpp, text-generation-webui, LlamaChat) / Performance / Others
- [ ] Due to frequent dependency updates, please ensure you have followed the steps in our [Wiki](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki)
- [ ] I have read the [FAQ section](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/FAQ) AND searched for similar issues and did not find a similar problem or solution
- [ ] Third-party plugin issues: e.g., [llama.cpp](https://github.com/ggerganov/llama.cpp), [text-generation-webui](https://github.com/oobabooga/text-generation-webui), [LlamaChat](https://github.com/alexrozanski/LlamaChat), we recommend checking the corresponding project for solutions
